<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>liquer.pool API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>liquer.pool</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import multiprocessing as mp
from multiprocessing.managers import BaseManager
from os import getpid
from time import sleep
from liquer.cache import set_cache, CacheProxy, NoCache
from liquer import *
from liquer.constants import *


class PoolManager(BaseManager):
    pass


PoolManager.register(&#34;CacheProxy&#34;, CacheProxy)

_pool = None


def start_pool(processes=None):
    global _pool
    _pool = mp.Pool(processes=processes)
    return _pool


def get_pool():
    global _pool
    if mp.current_process().name != &#34;MainProcess&#34;:
        raise Exception(&#34;Pool should only be accessed from the main process&#34;)
    if _pool is None:
        start_pool()
    return _pool


_worker_config = None


def get_cache(worker_config):
    print(f&#34;get_cache({worker_config})&#34;)
    if worker_config is None:
        print(&#34;worker config missing =&gt; No cache&#34;)
        return NoCache()
    if &#34;cache&#34; in worker_config:
        cache = worker_config[&#34;cache&#34;]
        print(f&#34;Central cache {repr(cache)}&#34;)
        return cache
    elif &#34;cache_constructor&#34; in worker_config:
        f = worker_config[&#34;cache_constructor&#34;]
        arg = worker_config.get(&#34;cache_arg&#34;, [])
        if arg is None:
            arg = []
        kwarg = worker_config.get(&#34;cache_kwarg&#34;, {})
        if kwarg is None:
            kwarg = {}
        cache = f(*arg, **kwarg)
        print(f&#34;Local cache {repr(cache)}&#34;)
        return cache
    else:
        print(f&#34;Worker confing missging cache description: {worker_config}&#34;)
    return NoCache()


def set_local_cache_constructor(constructor, arg=None, kwarg=None):
    &#34;&#34;&#34;Set the pool cache to use a locally constructed cache.
    This means that each pool worker will construct its cache locally
    applying arguments arg and keyword arguments kwarg to the constructor.
    This is suitable for FileCache (more or less) or a server-based cache (e.g. SQLCache with a database server),
    but it is not suitable for MemoryCache, since each worker will have its own memory cache and thus the cache will not be shared.

    In general this is a less secure solution. Even for FileCache there might be collisions if multiple workers
    try to access the same file. The set_central_cache should be a safe alternative.
    &#34;&#34;&#34;
    global _worker_config
    if _worker_config is None:
        _worker_config = {}
    _worker_config.update(
        dict(cache_constructor=constructor, cache_arg=arg, cache_kwarg=kwarg)
    )
    if arg is None:
        arg = []
    if kwarg is None:
        kwarg = {}
    cache = constructor(*arg, **kwarg)
    set_cache(cache)


def set_central_cache(cache, manager=None, use_cache_proxy_locally=True):
    &#34;&#34;&#34;Set the pool cache to use a cache object.
    The cache object lives in a single process, which is then accessed from workers using IPC.
    This is suitable for all types of cache objects, particularly it is important for a MemoryCache.

    In general this is a more secure solution, but it requires all data to support pickle.
    It has to be noted that the cache lives in a single process and relies on IPC to work, thus this solution
    may possibly be outperformed by set_local_cache_constructor.

    PoolManager instance can be provided via manager. If None, PoolManager will be created and started.
    The manager instance is returned.

    The use_cache_proxy_locally controls if cache is proxied when used locally (which should be the safe choice).
    &#34;&#34;&#34;
    global _worker_config
    if manager is None:
        manager = PoolManager()
        manager.start()
    if _worker_config is None:
        _worker_config = {}
    cache_proxy = manager.CacheProxy(cache)
    _worker_config.update(dict(cache=cache_proxy))
    if use_cache_proxy_locally:
        set_cache(cache_proxy)
    else:
        set_cache(cache)
    return manager


def _evaluate_worker(query, worker_config):
    print(f&#34;Evaluate worker started for {query}&#34;)
    set_cache(get_cache(worker_config))
    evaluate(query)
    return f&#34;Done evaluating {query}&#34;


def _evaluate_and_save_worker(query, target_directory, target_file, worker_config):
    print(f&#34;Evaluate and save worker started for {query}&#34;)
    set_cache(get_cache(worker_config))
    evaluate_and_save(query, target_directory=target_directory, target_file=target_file)
    return f&#34;Done evaluate and save {query}&#34;


def evaluate_in_background(query):
    &#34;&#34;&#34;Like evaluate, but returns immediately and runs in the background.
    Note that this creates immediately a submitted state in the cache.

    If there is no metadata associated with the query after calling this function,
    then either there is no cache or the resulting state is volatile.
    This can be used by GUI to identify situations when waiting for the result to appear
    in the cache is not a viable strategy, but requesting the object directly is necessary.
    &#34;&#34;&#34;
    global _worker_config
    print(f&#34;Evaluate {query} in background&#34;)
    metadata = get_context().metadata()
    metadata[&#34;query&#34;] = query
    metadata[&#34;status&#34;] = Status.SUBMITTED.value
    cache = get_cache(_worker_config)
    cache.store_metadata(metadata)

    if _worker_config is None:
        print(&#34;WARNING: Evaluated in main process&#34;)
        print(
            &#34;         Please configure the cache using set_local_cache_constructor or set_central_cache&#34;
        )
        return evaluate(query)
    else:
        return get_pool().apply_async(
            _evaluate_worker, [query, _worker_config], callback=print
        )


def evaluate_and_save_in_background(query, target_directory=None, target_file=None):
    &#34;&#34;&#34;Like evaluate_and_save, but returns immediately and runs in the background.
    Note that the saving occurs on o worker. Eventual remote workers will save the results in their local filesystem.
    &#34;&#34;&#34;
    global _worker_config
    print(f&#34;Evaluate and save {query} in background&#34;)
    if _worker_config is None:
        print(&#34;WARNING: Evaluated in main process&#34;)
        print(
            &#34;         Please configure the cache using set_local_cache_constructor or set_central_cache&#34;
        )
        return evaluate_and_save(
            query, target_directory=target_directory, target_file=target_file
        )
    return get_pool().apply_async(
        _evaluate_and_save_worker,
        [query, target_directory, target_file, _worker_config],
        callback=print,
    )</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="liquer.pool.evaluate_and_save_in_background"><code class="name flex">
<span>def <span class="ident">evaluate_and_save_in_background</span></span>(<span>query, target_directory=None, target_file=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Like evaluate_and_save, but returns immediately and runs in the background.
Note that the saving occurs on o worker. Eventual remote workers will save the results in their local filesystem.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def evaluate_and_save_in_background(query, target_directory=None, target_file=None):
    &#34;&#34;&#34;Like evaluate_and_save, but returns immediately and runs in the background.
    Note that the saving occurs on o worker. Eventual remote workers will save the results in their local filesystem.
    &#34;&#34;&#34;
    global _worker_config
    print(f&#34;Evaluate and save {query} in background&#34;)
    if _worker_config is None:
        print(&#34;WARNING: Evaluated in main process&#34;)
        print(
            &#34;         Please configure the cache using set_local_cache_constructor or set_central_cache&#34;
        )
        return evaluate_and_save(
            query, target_directory=target_directory, target_file=target_file
        )
    return get_pool().apply_async(
        _evaluate_and_save_worker,
        [query, target_directory, target_file, _worker_config],
        callback=print,
    )</code></pre>
</details>
</dd>
<dt id="liquer.pool.evaluate_in_background"><code class="name flex">
<span>def <span class="ident">evaluate_in_background</span></span>(<span>query)</span>
</code></dt>
<dd>
<div class="desc"><p>Like evaluate, but returns immediately and runs in the background.
Note that this creates immediately a submitted state in the cache.</p>
<p>If there is no metadata associated with the query after calling this function,
then either there is no cache or the resulting state is volatile.
This can be used by GUI to identify situations when waiting for the result to appear
in the cache is not a viable strategy, but requesting the object directly is necessary.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def evaluate_in_background(query):
    &#34;&#34;&#34;Like evaluate, but returns immediately and runs in the background.
    Note that this creates immediately a submitted state in the cache.

    If there is no metadata associated with the query after calling this function,
    then either there is no cache or the resulting state is volatile.
    This can be used by GUI to identify situations when waiting for the result to appear
    in the cache is not a viable strategy, but requesting the object directly is necessary.
    &#34;&#34;&#34;
    global _worker_config
    print(f&#34;Evaluate {query} in background&#34;)
    metadata = get_context().metadata()
    metadata[&#34;query&#34;] = query
    metadata[&#34;status&#34;] = Status.SUBMITTED.value
    cache = get_cache(_worker_config)
    cache.store_metadata(metadata)

    if _worker_config is None:
        print(&#34;WARNING: Evaluated in main process&#34;)
        print(
            &#34;         Please configure the cache using set_local_cache_constructor or set_central_cache&#34;
        )
        return evaluate(query)
    else:
        return get_pool().apply_async(
            _evaluate_worker, [query, _worker_config], callback=print
        )</code></pre>
</details>
</dd>
<dt id="liquer.pool.get_cache"><code class="name flex">
<span>def <span class="ident">get_cache</span></span>(<span>worker_config)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_cache(worker_config):
    print(f&#34;get_cache({worker_config})&#34;)
    if worker_config is None:
        print(&#34;worker config missing =&gt; No cache&#34;)
        return NoCache()
    if &#34;cache&#34; in worker_config:
        cache = worker_config[&#34;cache&#34;]
        print(f&#34;Central cache {repr(cache)}&#34;)
        return cache
    elif &#34;cache_constructor&#34; in worker_config:
        f = worker_config[&#34;cache_constructor&#34;]
        arg = worker_config.get(&#34;cache_arg&#34;, [])
        if arg is None:
            arg = []
        kwarg = worker_config.get(&#34;cache_kwarg&#34;, {})
        if kwarg is None:
            kwarg = {}
        cache = f(*arg, **kwarg)
        print(f&#34;Local cache {repr(cache)}&#34;)
        return cache
    else:
        print(f&#34;Worker confing missging cache description: {worker_config}&#34;)
    return NoCache()</code></pre>
</details>
</dd>
<dt id="liquer.pool.get_pool"><code class="name flex">
<span>def <span class="ident">get_pool</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_pool():
    global _pool
    if mp.current_process().name != &#34;MainProcess&#34;:
        raise Exception(&#34;Pool should only be accessed from the main process&#34;)
    if _pool is None:
        start_pool()
    return _pool</code></pre>
</details>
</dd>
<dt id="liquer.pool.set_central_cache"><code class="name flex">
<span>def <span class="ident">set_central_cache</span></span>(<span>cache, manager=None, use_cache_proxy_locally=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Set the pool cache to use a cache object.
The cache object lives in a single process, which is then accessed from workers using IPC.
This is suitable for all types of cache objects, particularly it is important for a MemoryCache.</p>
<p>In general this is a more secure solution, but it requires all data to support pickle.
It has to be noted that the cache lives in a single process and relies on IPC to work, thus this solution
may possibly be outperformed by set_local_cache_constructor.</p>
<p>PoolManager instance can be provided via manager. If None, PoolManager will be created and started.
The manager instance is returned.</p>
<p>The use_cache_proxy_locally controls if cache is proxied when used locally (which should be the safe choice).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_central_cache(cache, manager=None, use_cache_proxy_locally=True):
    &#34;&#34;&#34;Set the pool cache to use a cache object.
    The cache object lives in a single process, which is then accessed from workers using IPC.
    This is suitable for all types of cache objects, particularly it is important for a MemoryCache.

    In general this is a more secure solution, but it requires all data to support pickle.
    It has to be noted that the cache lives in a single process and relies on IPC to work, thus this solution
    may possibly be outperformed by set_local_cache_constructor.

    PoolManager instance can be provided via manager. If None, PoolManager will be created and started.
    The manager instance is returned.

    The use_cache_proxy_locally controls if cache is proxied when used locally (which should be the safe choice).
    &#34;&#34;&#34;
    global _worker_config
    if manager is None:
        manager = PoolManager()
        manager.start()
    if _worker_config is None:
        _worker_config = {}
    cache_proxy = manager.CacheProxy(cache)
    _worker_config.update(dict(cache=cache_proxy))
    if use_cache_proxy_locally:
        set_cache(cache_proxy)
    else:
        set_cache(cache)
    return manager</code></pre>
</details>
</dd>
<dt id="liquer.pool.set_local_cache_constructor"><code class="name flex">
<span>def <span class="ident">set_local_cache_constructor</span></span>(<span>constructor, arg=None, kwarg=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Set the pool cache to use a locally constructed cache.
This means that each pool worker will construct its cache locally
applying arguments arg and keyword arguments kwarg to the constructor.
This is suitable for FileCache (more or less) or a server-based cache (e.g. SQLCache with a database server),
but it is not suitable for MemoryCache, since each worker will have its own memory cache and thus the cache will not be shared.</p>
<p>In general this is a less secure solution. Even for FileCache there might be collisions if multiple workers
try to access the same file. The set_central_cache should be a safe alternative.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_local_cache_constructor(constructor, arg=None, kwarg=None):
    &#34;&#34;&#34;Set the pool cache to use a locally constructed cache.
    This means that each pool worker will construct its cache locally
    applying arguments arg and keyword arguments kwarg to the constructor.
    This is suitable for FileCache (more or less) or a server-based cache (e.g. SQLCache with a database server),
    but it is not suitable for MemoryCache, since each worker will have its own memory cache and thus the cache will not be shared.

    In general this is a less secure solution. Even for FileCache there might be collisions if multiple workers
    try to access the same file. The set_central_cache should be a safe alternative.
    &#34;&#34;&#34;
    global _worker_config
    if _worker_config is None:
        _worker_config = {}
    _worker_config.update(
        dict(cache_constructor=constructor, cache_arg=arg, cache_kwarg=kwarg)
    )
    if arg is None:
        arg = []
    if kwarg is None:
        kwarg = {}
    cache = constructor(*arg, **kwarg)
    set_cache(cache)</code></pre>
</details>
</dd>
<dt id="liquer.pool.start_pool"><code class="name flex">
<span>def <span class="ident">start_pool</span></span>(<span>processes=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def start_pool(processes=None):
    global _pool
    _pool = mp.Pool(processes=processes)
    return _pool</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="liquer.pool.PoolManager"><code class="flex name class">
<span>class <span class="ident">PoolManager</span></span>
<span>(</span><span>address=None, authkey=None, serializer='pickle', ctx=None, *, shutdown_timeout=1.0)</span>
</code></dt>
<dd>
<div class="desc"><p>Base class for managers</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class PoolManager(BaseManager):
    pass</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>multiprocessing.managers.BaseManager</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="liquer.pool.PoolManager.CacheProxy"><code class="name flex">
<span>def <span class="ident">CacheProxy</span></span>(<span>self, /, *args, **kwds)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def temp(self, /, *args, **kwds):
    util.debug(&#39;requesting creation of a shared %r object&#39;, typeid)
    token, exp = self._create(typeid, *args, **kwds)
    proxy = proxytype(
        token, self._serializer, manager=self,
        authkey=self._authkey, exposed=exp
        )
    conn = self._Client(token.address, authkey=self._authkey)
    dispatch(conn, None, &#39;decref&#39;, (token.id,))
    return proxy</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="liquer" href="index.html">liquer</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="liquer.pool.evaluate_and_save_in_background" href="#liquer.pool.evaluate_and_save_in_background">evaluate_and_save_in_background</a></code></li>
<li><code><a title="liquer.pool.evaluate_in_background" href="#liquer.pool.evaluate_in_background">evaluate_in_background</a></code></li>
<li><code><a title="liquer.pool.get_cache" href="#liquer.pool.get_cache">get_cache</a></code></li>
<li><code><a title="liquer.pool.get_pool" href="#liquer.pool.get_pool">get_pool</a></code></li>
<li><code><a title="liquer.pool.set_central_cache" href="#liquer.pool.set_central_cache">set_central_cache</a></code></li>
<li><code><a title="liquer.pool.set_local_cache_constructor" href="#liquer.pool.set_local_cache_constructor">set_local_cache_constructor</a></code></li>
<li><code><a title="liquer.pool.start_pool" href="#liquer.pool.start_pool">start_pool</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="liquer.pool.PoolManager" href="#liquer.pool.PoolManager">PoolManager</a></code></h4>
<ul class="">
<li><code><a title="liquer.pool.PoolManager.CacheProxy" href="#liquer.pool.PoolManager.CacheProxy">CacheProxy</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>